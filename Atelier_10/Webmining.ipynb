{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Web Mining: principes de bases\n",
    "\n",
    "Le webmining est donc une technique qui repose sur les technologies du web et qui rentre dans la catégorie de  l'extraction et analyse de données (Text and Data Mining).\n",
    "\n",
    "Le [cadre légal](Atelier_10.md) de cette pratique est assez complexe \n",
    "\n",
    "Les principales opérations consistent à:\n",
    "\n",
    "-   se **connecter** à une page web et charger le html (load, connect) dans le cas de page statique c'est une opération  simple, dans le cas de page dynamique c'est une autre paire de manches...\n",
    "-   **parcourir la page** et **extraire** les informations cibles   (celles qui nous intéressent: ce qui implique d'avoir identifiés au préalalble les informations qui nous intéresse dans la page soit les balises )\n",
    "- les **stocker** dans un fichier ou une base de données en les organisant selon ce qui nous arrange pour l'analyse\n",
    "\n",
    "L'objectif final étant de récupérer des informations pour les **analyser**. Ici [plein de techniques](./WebAnalysis.ipynb) s'appliquent en fonction de l'analyse qu'on veut en faire.\n",
    "\n",
    "Nous allons d'abord installer dans le système, les modules complémentaires dont nous avons besoin. \n",
    "Dans le terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: lxml in /usr/lib/python3/dist-packages\n",
      "Requirement already satisfied: BeautifulSoup4 in /usr/lib/python3/dist-packages\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/bash\n",
    "\n",
    "! pip install requests lxml BeautifulSoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Télécharger une page web statique\n",
    "\n",
    "### URL => PAGE HTML\n",
    "\n",
    "La première étape est de se connecter à la page web et de télécharger le code source de la page.\n",
    "On va donc à partir d'une url, télécharger une page html. \n",
    "\n",
    "Plusieurs modules pour faire des requêtes avec python existent: \n",
    "le plus simple étant le module [**requests**](http://docs.python-requests.org/en/master/)\n",
    "\n",
    "Ce module télécharge la page demandée  à partir d'une url. Il donne aussi des informations contextuelles sur la requête: le code renvoyé par le serveur, ce qui peut être bien pratique en cas d'erreur.\n",
    "\n",
    "Nous allons écrire une fonction download() qui prend une page web en argument et retourne True et la page **html** si tout c'est bien passé et False, et le code d'erreur HTPP si cela ne s'est pas bien passé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def download(url=\"http://www.marmiton.org/recettes/recette_veloute-chou-fleur-coco-sesame_346982.aspx\"):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return (True, response.text)\n",
    "    else:\n",
    "        return (False, response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#on instancie la fonction avce une url\n",
    "url = \"http://www.marmiton.org/recettes/recette_veloute-chou-fleur-coco-sesame_346982.aspx\"\n",
    "response, page_html = download(url)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Identifier les informations pertinentes\n",
    "### Page HTML => DOM Inspector\n",
    "\n",
    "Nous avons récupéré la page HTML désirée, il s'agit pour le moment de HTML soit un arbre DOM (du texte et des balises HTML). Pour extraire les informations qui nous intéressent: \n",
    "il nous faut détecter les informations qui nous intéresse : dans quelles balises et à quel niveau du document\n",
    "On utilise le DOM Inspector en général (l'exorateur de code de votre navigateur): \n",
    "Ouvrez votre navigateur: tapez F12 et inspecter la page web lister les informations que vous souhaitez extraire.\n",
    "\n",
    "## Parser la page html\n",
    "\n",
    "### Page HTML => DOM \n",
    "\n",
    "On a récupéré la page web, il faut parcourir le code HTML avec un parser. On va utiliser **BeautifulSoup** un module qui donne des méthodes simples pour accéder aux éléments html qui nous intéressent et qui repose sur un parser standard **lxml**. Nous les avons déjà installé nous allons donc mettre le code source de la page HTML dans un parser. Nous allons créer une fonction parse qui prend la page html et parser le code pour pouvoir le manipuler ensuite grace aux méthodes du module BeautifulSoup et extraure les informations dont on a besoin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BeautifulSoup4 import BeautifulSoup\n",
    "def parse(page_html):\n",
    "    '''on transforme une page html en une *soupe* avce des tags quon peut rechercher '''\n",
    "    soup = BeautifulSoup(page_html, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#on instancie la fonction en se servant des fonctions déjà écrites\n",
    "\n",
    "url = \"http://www.marmiton.org/recettes/recette_veloute-chou-fleur-coco-sesame_346982.aspx\"\n",
    "response, page_html = download(url)\n",
    "print(response)\n",
    "soup = parse(page_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Extraire les informations du HTML\n",
    "\n",
    "### DOM  Tags=> elements textuels\n",
    "\n",
    "A cette étape, il est utile de connaitre le HTML. \n",
    "Une fois qu'on a identifié les balises qui contiennent les éléments textuels qu'on veut extraire, on va les chercher et les stocker à l'aide des méthodes de BeautifulSoup find(), findAll(), get().\n",
    "\n",
    "Ici on crée une fonction qui permet d'extraire:\n",
    "- le titre de la page\n",
    "- la liste des ingrédients, \n",
    "- le temps de préparation \n",
    "- le temps de cuission \n",
    "- les instructins de la recette \n",
    "en fonction du type de tag et de la classe de la balise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_recette(soup):\n",
    "    '''cette fonction est spécifique à marmiton'''\n",
    "    titre = soup.find(\"h1\", {\"class\":\"m_title fn\"})\n",
    "    print(\"titre\", titre.text)\n",
    "    #ici on transforme une liste en chaine de caractère séparé par une virgule\n",
    "    ingredients =  \",\".join([n.text() for n in soup.findAll(\"a\", {\"class\":\"mrm_al\"})])\n",
    "    print(\"ingredients\", ingredients)\n",
    "    preparation_t = soup.find(\"span\", {\"class\":\"preptime\"}).text()\n",
    "    print(\"temps de preparation\", preparation_t)\n",
    "    cuisson_t = soup.find(\"span\", {\"class\":\"cooktime\"}).text()\n",
    "    print(\"temps de cuission\", cuisson_t)\n",
    "    instructions = soup.find(\"div\", {\"class\": \"m_content_recette_todo\"}).text()\n",
    "    print(\"instructions\", instructions)\n",
    "    return (titre, ingredients, preparation_t, cuisson_t, instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#on instancie la fonction en se servant des fonctions déjà écrites\n",
    "\n",
    "url = \"http://www.marmiton.org/recettes/recette_veloute-chou-fleur-coco-sesame_346982.aspx\"\n",
    "response, page_html = download(url)\n",
    "print(response)\n",
    "soup = parse(page_html)\n",
    "recette = extract_recette(soup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrer et stocker les informations\n",
    "\n",
    "### elements textuels => fichier\n",
    "Une fois ses informatiosn extraite on peut la stocker en écrivant les résultats dans un fichier ou une base de données. Ici pour l'exemple ou va stocker la recette dans un CSV séparé par des tabulations en créant une fonction store_results qui prend les resultats et le nom du fichier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def store_results(results, file_name):\n",
    "    #on ouvre un file descriptor et on met l'option 'a' pour append : soit écrire à la suite\n",
    "    with open(file, \"a\") as f:\n",
    "        #transforme la ligne de resultats en chaine de caractère séparée par une tabulation\n",
    "        line = \"\\t\".join(results)\n",
    "        #ecris dans un fichier la ligne et ajoute un retour à la ligne\n",
    "        f.write(+\"\\n\")\n",
    "    return \n",
    "    \n",
    "#on instancie la fonction en se servant des fonctions déjà écrites\n",
    "url = \"http://www.marmiton.org/recettes/recette_veloute-chou-fleur-coco-sesame_346982.aspx\"\n",
    "response, page_html = download(url)\n",
    "if response is True:\n",
    "    soup = parse(page_html)\n",
    "    recette = extract_recette(soup)\n",
    "    store_results(\"./recettes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
